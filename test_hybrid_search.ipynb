{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Jupyter\\Upwork\\DocumentQA\\DocumentQA\\venv\\lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone, PodSpec \n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from hybrid_pinecone import HybridPinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "We use langchain PDF loaders to read pdfs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"data/E1. ExngTextOnly.pdf\"\n",
    "loader = PyMuPDFLoader(filepath)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = [document.page_content for document in documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse and Dense Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "from transformers import BertTokenizerFast              # Sparse Embeddings\n",
    "from sentence_transformers import SentenceTransformer   # Dense Embeddings\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPARSE EMBEDDINGS\n",
    "\n",
    "# load bert tokenizer from huggingface\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\n",
    "    'bert-base-uncased'\n",
    ")\n",
    "\n",
    "inputs = tokenizer(\n",
    "    contexts[0], padding=True, truncation=True,\n",
    "    max_length=512\n",
    ")\n",
    "inputs.keys()\n",
    "\n",
    "\n",
    "# extract the input ids\n",
    "input_ids = inputs['input_ids']\n",
    "\n",
    "# convert the input_ids list to a dictionary of key to frequency values\n",
    "sparse_vec = dict(Counter(input_ids))\n",
    "sparse_vec\n",
    "def build_dict(input_batch):\n",
    " # store a batch of sparse embeddings\n",
    "   sparse_emb = []\n",
    "   # iterate through input batch\n",
    "   for token_ids in input_batch:\n",
    "       indices = []\n",
    "       values = []\n",
    "       # convert the input_ids list to a dictionary of key to frequency values\n",
    "       d = dict(Counter(token_ids))\n",
    "       for idx in d:\n",
    "            indices.append(idx)\n",
    "            values.append(float(d[idx]))                        # Extremely important to cast values as float\n",
    "                                                                # Otherwise you get: SparseValuesMissingKeysError: Missing required keys in data in column `sparse_values`.\n",
    "       sparse_emb.append({'indices': indices, 'values': values})\n",
    "   # return sparse_emb list\n",
    "   return sparse_emb\n",
    "\n",
    "def generate_sparse_vectors(context_batch):\n",
    "    \"\"\"\n",
    "    create batch of input_ids required by pinecone for sparse vector sotrage\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(\n",
    "            context_batch, padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512\n",
    "    )['input_ids']\n",
    "    # create sparse dictionaries\n",
    "    sparse_embeds = build_dict(inputs)\n",
    "    return sparse_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DENSE EMBEDDINGS\n",
    "\n",
    "# load a sentence transformer model from huggingface\n",
    "model = SentenceTransformer(\n",
    "    'multi-qa-MiniLM-L6-cos-v1',\n",
    "    device='cpu'                    # or cuda, if available\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = HybridPinecone(\n",
    "    api_key = \"3c9fd500-de4d-40ed-8c77-12302b71e8ce\",  # app.pinecone.io\n",
    "    environment = \"gcp-starter\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"hybrid-test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [201]>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# create the index\n",
    "pc.create_index(\n",
    "   index_name = index_name,\n",
    "   dimension = 384,  # dimensionality of dense model\n",
    "   pod_type='p1',\n",
    "   metric = \"dotproduct\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(\n",
    "    api_key = \"3c9fd500-de4d-40ed-8c77-12302b71e8ce\",  # app.pinecone.io\n",
    "    environment = \"gcp-starter\"\n",
    ")\n",
    "index = pc.Index(name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.61s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 50\n",
    "\n",
    "for i in tqdm(range(0, len(contexts), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(i+batch_size, len(contexts))\n",
    "    # extract batch\n",
    "    context_batch = contexts[i:i_end]\n",
    "    # create unique IDs\n",
    "    ids = [str(x) for x in range(i, i_end)]\n",
    "    # add context passages as metadata\n",
    "    meta = [{'context': context} for context in context_batch]\n",
    "    # create dense vectors\n",
    "    dense_embeds = model.encode(context_batch).tolist()\n",
    "    # create sparse vectors\n",
    "    sparse_embeds = generate_sparse_vectors(context_batch)\n",
    "\n",
    "    vectors = []\n",
    "    # loop through the data and create dictionaries for uploading documents to pinecone index\n",
    "    for _id, sparse, dense, metadata in zip(ids, sparse_embeds, dense_embeds, meta):\n",
    "        vectors.append({\n",
    "            'id': _id,\n",
    "            'sparse_values': sparse,\n",
    "            'values': dense,\n",
    "            'metadata': metadata\n",
    "        })\n",
    "\n",
    "    # upload the documents to the new hybrid index\n",
    "    index.upsert(vectors)\n",
    "\n",
    "# show index description after uploading the documents\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hybrid_query(question, top_k, alpha):\n",
    "#     # convert the question into a sparse vector\n",
    "#     sparse_vec = generate_sparse_vectors([question])\n",
    "#     # convert the question into a dense vector\n",
    "#     dense_vec = model.encode([question]).tolist()\n",
    "#     # set the query parameters to send to pinecone\n",
    "#     query = {\n",
    "#       \"topK\": top_k,\n",
    "#       \"vector\": dense_vec,\n",
    "#       \"sparseVector\": sparse_vec[0],\n",
    "#       \"alpha\": alpha,\n",
    "#       \"includeMetadata\": True\n",
    "#     }\n",
    "#     # query pinecone with the query parameters\n",
    "#     result = index.query(query)\n",
    "#     # return search results as json\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What did willy wonka do with vitawonk?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse = generate_sparse_vectors([question])[0]\n",
    "alpha = 0.4\n",
    "[v * (1 - alpha) for v in sparse['values']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.022238956391811372,\n",
       " 0.062448978424072266,\n",
       " 0.006351868063211441,\n",
       " -0.0016900459304451942,\n",
       " -0.02263036072254181,\n",
       " 0.02233632951974869,\n",
       " 0.019580307602882388,\n",
       " 0.007697943598031998,\n",
       " -0.007668163627386093,\n",
       " 0.00793217122554779,\n",
       " -0.011692066490650178,\n",
       " -0.0307610422372818,\n",
       " 0.002302438206970692,\n",
       " -0.021654368937015535,\n",
       " 0.023146696388721466,\n",
       " -0.004521287232637406,\n",
       " 0.00912071466445923,\n",
       " 0.018840651214122775,\n",
       " -0.016990162432193756,\n",
       " -0.026402932405471802,\n",
       " -0.0208988755941391,\n",
       " -0.00027084730099886657,\n",
       " 0.016845071315765382,\n",
       " 0.0035627253353595735,\n",
       " -0.01064179316163063,\n",
       " 0.002639190107584,\n",
       " 0.029694929718971252,\n",
       " 0.0060277082026004795,\n",
       " 0.006275960057973862,\n",
       " -0.02002657949924469,\n",
       " -0.024647326767444612,\n",
       " -0.004160820692777634,\n",
       " -0.014814341068267824,\n",
       " -0.0073359027504920965,\n",
       " -0.02858361899852753,\n",
       " 0.020740592479705812,\n",
       " -0.009042345732450486,\n",
       " 0.011702513694763184,\n",
       " -0.025087690353393557,\n",
       " -0.013969555497169495,\n",
       " 0.028975486755371094,\n",
       " -0.011495745927095414,\n",
       " 0.0028424883261322976,\n",
       " -0.006520325690507889,\n",
       " 0.006218633428215981,\n",
       " -0.01995483785867691,\n",
       " -0.021756209433078766,\n",
       " -0.012190362066030504,\n",
       " -0.015802808105945587,\n",
       " 0.012893280386924744,\n",
       " 0.0035006687045097355,\n",
       " -0.011839608848094941,\n",
       " 0.008461152762174606,\n",
       " -0.02560894787311554,\n",
       " 0.008129575848579406,\n",
       " -0.03203988075256348,\n",
       " 0.028783175349235537,\n",
       " 0.04424550831317902,\n",
       " 0.02990224063396454,\n",
       " 0.023032425343990328,\n",
       " -0.0009041125886142254,\n",
       " 0.006597994267940522,\n",
       " -0.00012894001556560398,\n",
       " -0.00039924904704093935,\n",
       " -0.0060951031744480135,\n",
       " -0.05471527576446533,\n",
       " -0.01856810599565506,\n",
       " 0.003568808361887932,\n",
       " -0.030664154887199403,\n",
       " -0.0028548339381814004,\n",
       " 0.02073463499546051,\n",
       " -0.010348750650882721,\n",
       " 0.04231181740760803,\n",
       " -0.0009392939507961274,\n",
       " -0.011968625336885454,\n",
       " -0.031429752707481384,\n",
       " -0.02057778835296631,\n",
       " 0.002388514205813408,\n",
       " -0.005384190753102303,\n",
       " -0.00450487993657589,\n",
       " 0.00020914135966449977,\n",
       " -0.022483982145786285,\n",
       " -0.03593520224094391,\n",
       " 0.015621381998062135,\n",
       " -0.023434802889823914,\n",
       " 0.020770451426506045,\n",
       " -0.01105109229683876,\n",
       " -0.0006211754865944386,\n",
       " 0.016481153666973114,\n",
       " -0.0026807570829987526,\n",
       " -0.004119961336255073,\n",
       " 0.006831362098455429,\n",
       " -0.0010759380646049976,\n",
       " 0.013615070283412934,\n",
       " 0.0013903362676501276,\n",
       " 0.017965039610862734,\n",
       " -0.008312775194644928,\n",
       " 0.0008913631550967694,\n",
       " -0.005753835663199425,\n",
       " 0.009667453914880754,\n",
       " 0.009645608812570573,\n",
       " 0.00282378401607275,\n",
       " 0.010799489170312883,\n",
       " -0.01254410594701767,\n",
       " 0.013042797148227692,\n",
       " -0.0007154997903853655,\n",
       " -0.0014584150165319444,\n",
       " -0.027568140625953676,\n",
       " 0.024572095274925234,\n",
       " 0.016658663749694824,\n",
       " -0.028221127390861512,\n",
       " -0.022909626364707947,\n",
       " 0.006754519045352936,\n",
       " 0.005958540365099907,\n",
       " 0.0029836444184184077,\n",
       " 0.024724590778350833,\n",
       " -0.030734103918075562,\n",
       " -0.004919406399130822,\n",
       " -0.009111588448286056,\n",
       " -0.030971843004226687,\n",
       " 0.05035640597343445,\n",
       " -0.01683194935321808,\n",
       " -0.013645261526107788,\n",
       " -0.004702678322792054,\n",
       " 0.006919806450605393,\n",
       " 0.015529349446296692,\n",
       " 0.003959532082080841,\n",
       " 3.8994931768189447e-31,\n",
       " 0.002112565375864506,\n",
       " 0.0004120331257581711,\n",
       " 0.012781654298305512,\n",
       " 0.05474427342414856,\n",
       " -0.01005137786269188,\n",
       " -0.007987026125192642,\n",
       " -0.004372457414865494,\n",
       " -0.014122100174427034,\n",
       " -0.015801656246185302,\n",
       " 0.0031757351011037827,\n",
       " -0.0171752467751503,\n",
       " 0.001133230235427618,\n",
       " -0.057135003805160525,\n",
       " 0.021529124677181245,\n",
       " -0.023617982864379883,\n",
       " 0.008818215876817704,\n",
       " -0.048960500955581666,\n",
       " -0.03738626539707184,\n",
       " 0.003662987053394318,\n",
       " 0.021680946648120883,\n",
       " 0.04201844930648804,\n",
       " 0.03369612097740173,\n",
       " -0.0341731995344162,\n",
       " 0.004060491546988488,\n",
       " -0.008995157480239869,\n",
       " 0.032555592060089115,\n",
       " 0.025056666135787966,\n",
       " -0.023153591156005862,\n",
       " 0.008831318467855453,\n",
       " 0.027965745329856875,\n",
       " -0.016367898881435396,\n",
       " 0.006117373332381249,\n",
       " -0.030631181597709656,\n",
       " -0.01820269823074341,\n",
       " -0.009222237765789032,\n",
       " -0.0018130706623196602,\n",
       " -0.03175555467605591,\n",
       " -0.02431275248527527,\n",
       " -0.05267232060432434,\n",
       " 0.010971451550722123,\n",
       " 0.019817134737968447,\n",
       " 0.0003256086260080338,\n",
       " -0.04222636222839356,\n",
       " 0.0028254639357328418,\n",
       " -0.019961997866630554,\n",
       " -0.006228354573249818,\n",
       " -0.0019065391272306443,\n",
       " -0.010449484735727311,\n",
       " 0.059902495145797735,\n",
       " 0.030475884675979614,\n",
       " 0.006667228788137436,\n",
       " -0.016665345430374148,\n",
       " 0.015260712802410127,\n",
       " -0.0006334887351840735,\n",
       " 0.008108310401439667,\n",
       " 0.005315633118152619,\n",
       " -0.00229652114212513,\n",
       " 0.0001481798244640231,\n",
       " -0.006994555145502091,\n",
       " 0.012744817137718202,\n",
       " 0.04855139255523682,\n",
       " -0.007023344933986664,\n",
       " 0.018780432641506195,\n",
       " 0.05954281091690064,\n",
       " -0.007921496778726578,\n",
       " -0.00553688369691372,\n",
       " -0.003903232887387276,\n",
       " 0.02451392561197281,\n",
       " -0.004541916400194169,\n",
       " -0.025659364461898804,\n",
       " 0.0011089744977653027,\n",
       " 0.010766104608774186,\n",
       " -0.028971654176712037,\n",
       " -0.036726027727127075,\n",
       " -0.03223505616188049,\n",
       " -0.02885780930519104,\n",
       " -0.023313485085964203,\n",
       " 0.0323503315448761,\n",
       " -0.007744745165109635,\n",
       " -0.005868424847722054,\n",
       " 0.02962618172168732,\n",
       " -0.006943356245756149,\n",
       " 0.012682031095027925,\n",
       " 0.004603982344269753,\n",
       " -0.0031645141541957857,\n",
       " 0.021518796682357788,\n",
       " -0.003953257948160172,\n",
       " 0.0019335463643074037,\n",
       " -0.006513042747974396,\n",
       " -0.001513685192912817,\n",
       " -0.012204649299383164,\n",
       " 0.020522876083850863,\n",
       " 0.002476291358470917,\n",
       " -0.008711187541484833,\n",
       " -0.015301381051540375,\n",
       " -1.2045856319532313e-33,\n",
       " -0.005197840556502343,\n",
       " 0.005143711715936661,\n",
       " 0.02610236704349518,\n",
       " 0.043154370784759526,\n",
       " 0.017793203890323638,\n",
       " -0.015819920599460604,\n",
       " -0.004150249436497689,\n",
       " 0.021415190398693086,\n",
       " 0.0068068914115428925,\n",
       " -0.01621783822774887,\n",
       " -0.011056517809629442,\n",
       " -0.005525154620409012,\n",
       " 0.029374897480010986,\n",
       " -0.006544672697782517,\n",
       " 0.014451609551906587,\n",
       " -0.03381121754646301,\n",
       " 0.03301626741886139,\n",
       " 0.010351044684648515,\n",
       " 0.007320660352706909,\n",
       " -0.0013931727036833764,\n",
       " -0.007655484974384308,\n",
       " 0.02758366167545319,\n",
       " 0.007986222207546235,\n",
       " -0.0053820256143808365,\n",
       " -0.03313754796981812,\n",
       " 0.002948146127164364,\n",
       " -0.00024929053615778684,\n",
       " 0.006606936454772949,\n",
       " -0.03366973400115967,\n",
       " 0.020911698043346406,\n",
       " 0.025965866446495057,\n",
       " -0.0055094450712203985,\n",
       " -0.01924801617860794,\n",
       " 0.020043624937534334,\n",
       " -0.011082801967859268,\n",
       " -0.027511972188949588,\n",
       " 0.006685084849596024,\n",
       " 0.0046991769224405296,\n",
       " -0.01669261455535889,\n",
       " -0.02038514018058777,\n",
       " 0.0054361578077077866,\n",
       " -0.04116218984127045,\n",
       " 0.004353498667478562,\n",
       " 0.03220809698104859,\n",
       " 0.0004029745236039162,\n",
       " 0.012591202557086945,\n",
       " -0.005154365301132203,\n",
       " -0.01227124035358429,\n",
       " 0.03512930572032929,\n",
       " 0.011696777492761613,\n",
       " 0.024191811680793762,\n",
       " 0.006146286427974702,\n",
       " -0.014303806424140931,\n",
       " 0.008987498283386231,\n",
       " -0.012225862592458725,\n",
       " 0.008907628804445266,\n",
       " 0.012016605585813522,\n",
       " -0.0016021870076656343,\n",
       " 0.03305507004261017,\n",
       " 0.014485476911067963,\n",
       " -0.026260948181152346,\n",
       " -0.006864136457443238,\n",
       " -0.003129404410719872,\n",
       " 0.008452989906072617,\n",
       " -0.00617949590086937,\n",
       " 0.044090342521667485,\n",
       " 0.027116408944129946,\n",
       " 0.03386263251304627,\n",
       " 0.007189612835645676,\n",
       " 0.011443978548049927,\n",
       " 0.024030399322509766,\n",
       " 0.01582041084766388,\n",
       " 0.013855162262916566,\n",
       " 0.005565129220485687,\n",
       " -0.01259070634841919,\n",
       " 0.050121748447418214,\n",
       " -0.029112529754638673,\n",
       " 0.026627016067504884,\n",
       " 0.008287458121776581,\n",
       " -0.002928956039249897,\n",
       " -0.02599729299545288,\n",
       " -0.02105384171009064,\n",
       " -0.04355054199695588,\n",
       " 0.013329610228538513,\n",
       " 0.004581024870276451,\n",
       " 0.0013695292174816132,\n",
       " -0.033328086137771606,\n",
       " -0.030400386452674868,\n",
       " 0.0016061639413237573,\n",
       " 0.014683893322944641,\n",
       " -0.012168677151203157,\n",
       " 0.018830743432044984,\n",
       " 0.01675163805484772,\n",
       " 0.002020832523703575,\n",
       " 0.00623750314116478,\n",
       " -1.1854115558497937e-33,\n",
       " -0.003790444135665894,\n",
       " -0.0018141193315386773,\n",
       " -0.03803017735481262,\n",
       " -0.013586975634098053,\n",
       " 0.0024560783058404922,\n",
       " -0.013029898703098298,\n",
       " -0.0044246621429920195,\n",
       " -0.006740069389343262,\n",
       " 0.02174704521894455,\n",
       " 0.03665688633918762,\n",
       " -0.020668838918209077,\n",
       " 0.018150289356708527,\n",
       " 0.0004927796311676502,\n",
       " 0.021430937945842745,\n",
       " 0.015574701130390167,\n",
       " -0.013963568210601808,\n",
       " 0.019951950013637546,\n",
       " 0.027631598711013797,\n",
       " -0.006700889766216279,\n",
       " 0.013510525226593018,\n",
       " 0.01481807678937912,\n",
       " -0.01803872436285019,\n",
       " 0.04048978090286255,\n",
       " -0.039556899666786195,\n",
       " -0.027809882164001466,\n",
       " -0.00731232762336731,\n",
       " -0.015055434405803682,\n",
       " 0.002518853731453419,\n",
       " 0.04642036855220795,\n",
       " -0.013653208315372468,\n",
       " 0.003980930522084237,\n",
       " -0.005374675616621971,\n",
       " -0.0279055655002594,\n",
       " -0.01768503785133362,\n",
       " -0.02837246358394623,\n",
       " 0.0018298443406820299,\n",
       " -0.006377039104700089,\n",
       " -0.03507369160652161,\n",
       " 0.010173214972019196,\n",
       " -0.009266836196184158,\n",
       " 0.004240713268518448,\n",
       " -0.01937660574913025,\n",
       " 0.0031658150255680084,\n",
       " -0.006813517957925797,\n",
       " -0.016473302245140077,\n",
       " 0.0014538532122969627,\n",
       " 0.007929370552301408,\n",
       " -0.010662884265184403,\n",
       " -0.03233833312988282,\n",
       " 0.014783582091331482,\n",
       " -0.04387654066085816,\n",
       " 0.023418766260147095,\n",
       " -0.016439451277256014,\n",
       " 0.014610910415649415,\n",
       " 0.0298851877450943,\n",
       " -0.009536480903625489,\n",
       " 0.036746343970298766,\n",
       " 0.024227178096771242,\n",
       " 0.007568576186895371,\n",
       " -0.00943581610918045,\n",
       " 0.011582617461681367,\n",
       " -0.01639150083065033,\n",
       " -0.003926972299814225,\n",
       " 0.008894483745098115]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense = model.encode([question]).tolist()[0]\n",
    "[v * alpha for v in dense]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_scale(dense, sparse, alpha: float):\n",
    "    # check alpha value is in range\n",
    "    if alpha < 0 or alpha > 1:\n",
    "        raise ValueError(\"Alpha must be between 0 and 1\")\n",
    "    # scale sparse and dense vectors to create hybrid search vecs\n",
    "    hsparse = {\n",
    "        'indices': sparse['indices'],\n",
    "        'values':  [v * (1 - alpha) for v in sparse['values']]\n",
    "    }\n",
    "    hdense = [v * alpha for v in dense]\n",
    "    return hdense, hsparse\n",
    "\n",
    "\n",
    "def hybrid_query(question, top_k, alpha):\n",
    "   # convert the question into a sparse vector\n",
    "   sparse_vec = generate_sparse_vectors([question])[0]\n",
    "   # convert the question into a dense vector\n",
    "   dense_vec = model.encode([question]).tolist()[0]\n",
    "   # scale alpha with hybrid_scale\n",
    "   dense_vec, sparse_vec = hybrid_scale(\n",
    "      dense_vec, sparse_vec, alpha\n",
    "   )\n",
    "   # query pinecone with the query parameters\n",
    "   result = index.query(\n",
    "      top_k=top_k,\n",
    "      vector=dense_vec,\n",
    "      sparse_vector=sparse_vec,\n",
    "      include_metadata=True\n",
    "   )\n",
    "   # return search results as json\n",
    "   return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '0',\n",
       "              'metadata': {'context': 'Who are the oldest people you know? '\n",
       "                                      'What are the\\n'\n",
       "                                      'oldest things you have (i) in your '\n",
       "                                      'house, (ii) in your city,\\n'\n",
       "                                      'town or village? How old are they?\\n'\n",
       "                                      'Have you ever wished that you were '\n",
       "                                      'older? Have\\n'\n",
       "                                      'you wished that you could grow up in a '\n",
       "                                      'hurry?\\n'\n",
       "                                      'Mr Willy Wonka begins by inventing '\n",
       "                                      'Wonka-\\n'\n",
       "                                      'Vite, which makes people younger. But '\n",
       "                                      'Wonka-\\n'\n",
       "                                      'Vite is too strong. So some people '\n",
       "                                      'disappear,\\n'\n",
       "                                      'because their age becomes Minus! One '\n",
       "                                      'person\\n'\n",
       "                                      'actually becomes minus eighty-seven, '\n",
       "                                      'which\\n'\n",
       "                                      'means he’s got to wait eighty-seven '\n",
       "                                      'years\\n'\n",
       "                                      'before he can come back.\\n'\n",
       "                                      'Mr Willy Wonka must invent a new '\n",
       "                                      'thing...\\n'\n",
       "                                      'Mr Wonka said, “So once again I rolled\\n'\n",
       "                                      'up my sleeves and set to work. Once\\n'\n",
       "                                      'again I squeezed my brain, searching '\n",
       "                                      'for the new\\n'\n",
       "                                      'recipe... I had to create age... to '\n",
       "                                      'make people old...\\n'\n",
       "                                      'old, older, oldest... ‘Ha-ha!’ I cried, '\n",
       "                                      'for now the\\n'\n",
       "                                      'ideas were beginning to come. ‘What is '\n",
       "                                      'the oldest\\n'\n",
       "                                      'living thing in the world? What lives '\n",
       "                                      'longer than\\n'\n",
       "                                      'anything else?’ ”\\n'\n",
       "                                      '“A tree,” Charlie said.\\n'\n",
       "                                      '“Right you are, Charlie! But what kind '\n",
       "                                      'of a\\n'\n",
       "                                      'tree? Not the Douglas fir. Not the oak. '\n",
       "                                      'Not the\\n'\n",
       "                                      'cedar. No, no, my boy. It is a tree '\n",
       "                                      'called the\\n'\n",
       "                                      'Bristlecone pine that grows upon the '\n",
       "                                      'slopes of\\n'\n",
       "                                      'Wheeler Peak in Nevada, U.S.A. You can '\n",
       "                                      'find\\n'\n",
       "                                      'Bristlecone Pines on Wheeler Peak today '\n",
       "                                      'that\\n'\n",
       "                                      'are over 4000 years old! This is fact, '\n",
       "                                      'Charlie. Ask\\n'\n",
       "                                      'any dendrochronologist you like (and '\n",
       "                                      'look that\\n'\n",
       "                                      'word up in the dictionary when you get '\n",
       "                                      'home,\\n'\n",
       "                                      'will you please?). So that started me '\n",
       "                                      'off. I\\n'\n",
       "                                      'jumped into the Great Glass Elevator '\n",
       "                                      'and\\n'\n",
       "                                      'rushed all over the world collecting '\n",
       "                                      'special items\\n'\n",
       "                                      'from the oldest living things...\\n'\n",
       "                                      ' A PINT OF SAP FROM A 4000-YEAR-OLD\\n'\n",
       "                                      'BRISTLECONE PINE\\n'\n",
       "                                      ' THE TOE-NAIL CLIPPINGS FROM A '\n",
       "                                      '168-YEAR-OLD\\n'\n",
       "                                      'RUSSIAN FARMER CALLED PETROVITCH\\n'\n",
       "                                      'GREGOROVITCH\\n'\n",
       "                                      ' AN EGG LAID BY A 200-YEAR-OLD '\n",
       "                                      'TORTOISE\\n'\n",
       "                                      'BELONGING TO THE KING OF TONGA\\n'\n",
       "                                      ' THE TAIL OF A 51-YEAR-OLD HORSE IN '\n",
       "                                      'ARABIA\\n'\n",
       "                                      ' THE WHISKERS OF A 36-YEAR-OLD CAT '\n",
       "                                      'CALLED\\n'\n",
       "                                      'CRUMPETS\\n'\n",
       "                                      ' AN OLD FLEA WHICH HAD LIVED ON '\n",
       "                                      'CRUMPETS\\n'\n",
       "                                      'FOR 36 YEARS\\n'\n",
       "                                      ' THE TAIL OF A 207-YEAR-OLD GIANT RAT '\n",
       "                                      'FROM\\n'\n",
       "                                      'TIBET\\n'\n",
       "                                      ' THE BLACK TEETH OF A 97-YEAR-OLD\\n'\n",
       "                                      'GRIMALKIN LIVING IN A CAVE ON MOUNT\\n'\n",
       "                                      'POPOCATEPETL\\n'\n",
       "                                      ' THE KNUCKLEBONES OF A 700-YEAR-OLD\\n'},\n",
       "              'score': 16.2882023,\n",
       "              'values': []},\n",
       "             {'id': '1',\n",
       "              'metadata': {'context': 'CATTALOO FROM PERU...”\\n'\n",
       "                                      '“All over the world, Charlie,” Mr Wonka '\n",
       "                                      'went on\\n'\n",
       "                                      '“I tracked down very old and ancient '\n",
       "                                      'animals and\\n'\n",
       "                                      'took an important little bit of '\n",
       "                                      'something from each\\n'\n",
       "                                      'one of them — a hair or an eyebrow or '\n",
       "                                      'sometimes\\n'\n",
       "                                      'it was no more than an ounce or two of '\n",
       "                                      'the jam\\n'\n",
       "                                      'scraped from between its toes while it '\n",
       "                                      'was\\n'\n",
       "                                      'sleeping. I tracked down THE '\n",
       "                                      'WHISTLE-PIG, THE\\n'\n",
       "                                      'BOBOLINK, THE SKROCK, THE POLLYFROG, '\n",
       "                                      'THE\\n'\n",
       "                                      'GIANT CURLICUE, THE STINGING SLUG AND '\n",
       "                                      'THE\\n'\n",
       "                                      'VENOMOUS SQUERKLE who can spit poison '\n",
       "                                      'right\\n'\n",
       "                                      'into your eye from fifty yards away. '\n",
       "                                      'But there’s\\n'\n",
       "                                      'no time to tell you about them all now, '\n",
       "                                      'Charlie.\\n'\n",
       "                                      'Let me just say quickly that in the '\n",
       "                                      'end, after lots\\n'\n",
       "                                      'of boiling and bubbling and mixing and '\n",
       "                                      'testing in\\n'\n",
       "                                      'my Inventing Room, I produced one tiny '\n",
       "                                      'cupful of\\n'\n",
       "                                      'oily black liquid and gave four drops '\n",
       "                                      'of it to a\\n'\n",
       "                                      'brave twenty-year-old Oompa-Loompa '\n",
       "                                      'volunteer\\n'\n",
       "                                      'to see what happened.”\\n'\n",
       "                                      '“What did happen?” Charlie asked.\\n'\n",
       "                                      '“It was fantastic!” cried Mr Wonka. '\n",
       "                                      '“The\\n'\n",
       "                                      'moment he swallowed it, he began '\n",
       "                                      'wrinkling and\\n'\n",
       "                                      'shrivelling up all over and his hair '\n",
       "                                      'started\\n'\n",
       "                                      'dropping off and his teeth started '\n",
       "                                      'falling out and,\\n'\n",
       "                                      'before I knew it, he had suddenly '\n",
       "                                      'become an old\\n'\n",
       "                                      'fellow of seventy-five! And thus, my '\n",
       "                                      'dear Charlie,\\n'\n",
       "                                      'was Vita-Wonk invented!”\\n'\n",
       "                                      'ROALD DAHL\\n'\n",
       "                                      '[from Charlie and the Great\\n'\n",
       "                                      'Glass Elevator]\\n'},\n",
       "              'score': 7.99711895,\n",
       "              'values': []}],\n",
       " 'namespace': '',\n",
       " 'usage': {'read_units': 6}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What did willy wonka do with vitawonk?\"\n",
    "\n",
    "# %% [markdown]\n",
    "# First, we will do a pure semantic search by setting the alpha value as 1.\n",
    "\n",
    "# %%\n",
    "hybrid_query(question, top_k=3, alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "documentqa",
   "language": "python",
   "name": "documentqa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
