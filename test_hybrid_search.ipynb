{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, PodSpec \n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from hybrid_pinecone import HybridPinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "We use langchain PDF loaders to read pdfs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"data/E1. ExngTextOnly.pdf\"\n",
    "loader = PyMuPDFLoader(filepath)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = [document.page_content for document in documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse and Dense Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "from transformers import BertTokenizerFast              # Sparse Embeddings\n",
    "from sentence_transformers import SentenceTransformer   # Dense Embeddings\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPARSE EMBEDDINGS\n",
    "\n",
    "# load bert tokenizer from huggingface\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\n",
    "    'bert-base-uncased'\n",
    ")\n",
    "\n",
    "inputs = tokenizer(\n",
    "    contexts[0], padding=True, truncation=True,\n",
    "    max_length=512\n",
    ")\n",
    "inputs.keys()\n",
    "\n",
    "\n",
    "# extract the input ids\n",
    "input_ids = inputs['input_ids']\n",
    "\n",
    "# convert the input_ids list to a dictionary of key to frequency values\n",
    "sparse_vec = dict(Counter(input_ids))\n",
    "sparse_vec\n",
    "def build_dict(input_batch):\n",
    " # store a batch of sparse embeddings\n",
    "   sparse_emb = []\n",
    "   # iterate through input batch\n",
    "   for token_ids in input_batch:\n",
    "       indices = []\n",
    "       values = []\n",
    "       # convert the input_ids list to a dictionary of key to frequency values\n",
    "       d = dict(Counter(token_ids))\n",
    "       for idx in d:\n",
    "            indices.append(idx)\n",
    "            values.append(float(d[idx]))                        # Extremely important to cast values as float\n",
    "                                                                # Otherwise you get: SparseValuesMissingKeysError: Missing required keys in data in column `sparse_values`.\n",
    "       sparse_emb.append({'indices': indices, 'values': values})\n",
    "   # return sparse_emb list\n",
    "   return sparse_emb\n",
    "\n",
    "def generate_sparse_vectors(context_batch):\n",
    "    \"\"\"\n",
    "    create batch of input_ids required by pinecone for sparse vector sotrage\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(\n",
    "            context_batch, padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512\n",
    "    )['input_ids']\n",
    "    # create sparse dictionaries\n",
    "    sparse_embeds = build_dict(inputs)\n",
    "    return sparse_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DENSE EMBEDDINGS\n",
    "\n",
    "# load a sentence transformer model from huggingface\n",
    "model = SentenceTransformer(\n",
    "    'multi-qa-MiniLM-L6-cos-v1',\n",
    "    device='cpu'                    # or cuda, if available\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = HybridPinecone(\n",
    "    api_key = \"3c9fd500-de4d-40ed-8c77-12302b71e8ce\",  # app.pinecone.io\n",
    "    environment = \"gcp-starter\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [201]>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"hybrid-test\"\n",
    "\n",
    "# create the index\n",
    "pc.create_index(\n",
    "   index_name = index_name,\n",
    "   dimension = 384,  # dimensionality of dense model\n",
    "   pod_type='p1',\n",
    "   metric = \"dotproduct\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(\n",
    "    api_key = \"3c9fd500-de4d-40ed-8c77-12302b71e8ce\",  # app.pinecone.io\n",
    "    environment = \"gcp-starter\"\n",
    ")\n",
    "index = pc.Index(name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.61s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 50\n",
    "\n",
    "for i in tqdm(range(0, len(contexts), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(i+batch_size, len(contexts))\n",
    "    # extract batch\n",
    "    context_batch = contexts[i:i_end]\n",
    "    # create unique IDs\n",
    "    ids = [str(x) for x in range(i, i_end)]\n",
    "    # add context passages as metadata\n",
    "    meta = [{'context': context} for context in context_batch]\n",
    "    # create dense vectors\n",
    "    dense_embeds = model.encode(context_batch).tolist()\n",
    "    # create sparse vectors\n",
    "    sparse_embeds = generate_sparse_vectors(context_batch)\n",
    "\n",
    "    vectors = []\n",
    "    # loop through the data and create dictionaries for uploading documents to pinecone index\n",
    "    for _id, sparse, dense, metadata in zip(ids, sparse_embeds, dense_embeds, meta):\n",
    "        vectors.append({\n",
    "            'id': _id,\n",
    "            'sparse_values': sparse,\n",
    "            'values': dense,\n",
    "            'metadata': metadata\n",
    "        })\n",
    "\n",
    "    # upload the documents to the new hybrid index\n",
    "    index.upsert(vectors)\n",
    "\n",
    "# show index description after uploading the documents\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_query(question, top_k, alpha):\n",
    "    # convert the question into a sparse vector\n",
    "    sparse_vec = generate_sparse_vectors([question])\n",
    "    # convert the question into a dense vector\n",
    "    dense_vec = model.encode([question]).tolist()\n",
    "    # set the query parameters to send to pinecone\n",
    "    query = {\n",
    "      \"topK\": top_k,\n",
    "      \"vector\": dense_vec,\n",
    "      \"sparseVector\": sparse_vec[0],\n",
    "      \"alpha\": alpha,\n",
    "      \"includeMetadata\": True\n",
    "    }\n",
    "    # query pinecone with the query parameters\n",
    "    result = index.query(query)\n",
    "    # return search results as json\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hybrid_scale(dense, sparse, alpha: float):\n",
    "#     # check alpha value is in range\n",
    "#     if alpha < 0 or alpha > 1:\n",
    "#         raise ValueError(\"Alpha must be between 0 and 1\")\n",
    "#     # scale sparse and dense vectors to create hybrid search vecs\n",
    "#     hsparse = {\n",
    "#         'indices': sparse['indices'],\n",
    "#         'values':  [v * (1 - alpha) for v in sparse['values']]\n",
    "#     }\n",
    "#     hdense = [v * alpha for v in dense]\n",
    "#     return hdense, hsparse\n",
    "\n",
    "\n",
    "# def hybrid_query(question, top_k, alpha):\n",
    "#    # convert the question into a sparse vector\n",
    "#    sparse_vec = generate_sparse_vectors([question])[0]\n",
    "#    # convert the question into a dense vector\n",
    "#    dense_vec = model.encode([question]).tolist()\n",
    "#    # scale alpha with hybrid_scale\n",
    "#    dense_vec, sparse_vec = hybrid_scale(\n",
    "#       dense_vec, sparse_vec, alpha\n",
    "#    )\n",
    "#    # query pinecone with the query parameters\n",
    "#    result = index.query(\n",
    "#       top_k=top_k,\n",
    "#       vector=dense_vec,\n",
    "#       sparse_vector=sparse_vec,\n",
    "#       include_metadata=True\n",
    "#    )\n",
    "#    # return search results as json\n",
    "#    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat did willy wonka do with vitawonk?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# %% [markdown]\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# First, we will do a pure semantic search by setting the alpha value as 1.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mhybrid_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[37], line 15\u001b[0m, in \u001b[0;36mhybrid_query\u001b[1;34m(question, top_k, alpha)\u001b[0m\n\u001b[0;32m      7\u001b[0m query \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      8\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopK\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_k,\n\u001b[0;32m      9\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvector\u001b[39m\u001b[38;5;124m\"\u001b[39m: dense_vec,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincludeMetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     13\u001b[0m }\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# query pinecone with the query parameters\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# return search results as json\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mf:\\Jupyter\\Upwork\\DocumentQA\\DocumentQA\\venv\\lib\\site-packages\\pinecone\\utils\\error_handling.py:10\u001b[0m, in \u001b[0;36mvalidate_and_convert_errors.<locals>.inner_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner_func\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 10\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m MaxRetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ProtocolError):\n",
      "File \u001b[1;32mf:\\Jupyter\\Upwork\\DocumentQA\\DocumentQA\\venv\\lib\\site-packages\\pinecone\\data\\index.py:386\u001b[0m, in \u001b[0;36mIndex.query\u001b[1;34m(self, top_k, vector, id, namespace, filter, include_values, include_metadata, sparse_vector, **kwargs)\u001b[0m\n\u001b[0;32m    371\u001b[0m sparse_vector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_sparse_values_arg(sparse_vector)\n\u001b[0;32m    372\u001b[0m args_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_non_empty_args(\n\u001b[0;32m    373\u001b[0m     [\n\u001b[0;32m    374\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvector\u001b[39m\u001b[38;5;124m\"\u001b[39m, vector),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    383\u001b[0m     ]\n\u001b[0;32m    384\u001b[0m )\n\u001b[0;32m    385\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vector_api\u001b[38;5;241m.\u001b[39mquery(\n\u001b[1;32m--> 386\u001b[0m     QueryRequest(\n\u001b[0;32m    387\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs_dict,\n\u001b[0;32m    388\u001b[0m         _check_type\u001b[38;5;241m=\u001b[39m_check_type,\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _OPENAPI_ENDPOINT_PARAMS},\n\u001b[0;32m    390\u001b[0m     ),\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _OPENAPI_ENDPOINT_PARAMS},\n\u001b[0;32m    392\u001b[0m )\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m parse_query_response(response)\n",
      "File \u001b[1;32mf:\\Jupyter\\Upwork\\DocumentQA\\DocumentQA\\venv\\lib\\site-packages\\pinecone\\core\\client\\model_utils.py:42\u001b[0m, in \u001b[0;36mconvert_js_args_to_python_args.<locals>.wrapped_init\u001b[1;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_property_naming:\n\u001b[0;32m     41\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m change_keys_js_to_python(kwargs, _self \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_self, \u001b[38;5;28mtype\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m _self\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(_self, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mf:\\Jupyter\\Upwork\\DocumentQA\\DocumentQA\\venv\\lib\\site-packages\\pinecone\\core\\client\\model\\query_request.py:301\u001b[0m, in \u001b[0;36mQueryRequest.__init__\u001b[1;34m(self, top_k, *args, **kwargs)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configuration \u001b[38;5;241m=\u001b[39m _configuration\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_visited_composed_classes \u001b[38;5;241m=\u001b[39m _visited_composed_classes \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m,)\n\u001b[1;32m--> 301\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtop_k\u001b[49m \u001b[38;5;241m=\u001b[39m top_k\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var_name, var_value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m var_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattribute_map \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    304\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configuration \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    305\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configuration\u001b[38;5;241m.\u001b[39mdiscard_unknown_keys \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    306\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madditional_properties_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;66;03m# discard variable.\u001b[39;00m\n",
      "File \u001b[1;32mf:\\Jupyter\\Upwork\\DocumentQA\\DocumentQA\\venv\\lib\\site-packages\\pinecone\\core\\client\\model_utils.py:181\u001b[0m, in \u001b[0;36mOpenApiModel.__setattr__\u001b[1;34m(self, attr, value)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr, value):\n\u001b[0;32m    180\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"set the value of an attribute using dot notation: `instance.attr = val`\"\"\"\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mattr\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m value\n",
      "File \u001b[1;32mf:\\Jupyter\\Upwork\\DocumentQA\\DocumentQA\\venv\\lib\\site-packages\\pinecone\\core\\client\\model_utils.py:481\u001b[0m, in \u001b[0;36mModelNormal.__setitem__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[name] \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 481\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_attribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\Jupyter\\Upwork\\DocumentQA\\DocumentQA\\venv\\lib\\site-packages\\pinecone\\core\\client\\model_utils.py:163\u001b[0m, in \u001b[0;36mOpenApiModel.set_attribute\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m    157\u001b[0m     check_allowed_values(\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallowed_values,\n\u001b[0;32m    159\u001b[0m         (name,),\n\u001b[0;32m    160\u001b[0m         value\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (name,) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidations:\n\u001b[1;32m--> 163\u001b[0m     \u001b[43mcheck_validations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_configuration\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_data_store\u001b[39m\u001b[38;5;124m'\u001b[39m][name] \u001b[38;5;241m=\u001b[39m value\n",
      "File \u001b[1;32mf:\\Jupyter\\Upwork\\DocumentQA\\DocumentQA\\venv\\lib\\site-packages\\pinecone\\core\\client\\model_utils.py:950\u001b[0m, in \u001b[0;36mcheck_validations\u001b[1;34m(validations, input_variable_path, input_values, configuration)\u001b[0m\n\u001b[0;32m    948\u001b[0m     min_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(input_values)\n\u001b[0;32m    949\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(input_values, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m--> 950\u001b[0m     max_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_values\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    951\u001b[0m     min_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(input_values\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[0;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: '>' not supported between instances of 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "question = \"What did willy wonka do with vitawonk?\"\n",
    "\n",
    "# %% [markdown]\n",
    "# First, we will do a pure semantic search by setting the alpha value as 1.\n",
    "\n",
    "# %%\n",
    "hybrid_query(question, top_k=3, alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "documentqa",
   "language": "python",
   "name": "documentqa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
